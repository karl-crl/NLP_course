{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "import pyLDAvis.gensim\n",
    "import re\n",
    "from typing import List\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что еще можно сделать:\n",
    "1) Попробовать NMF\n",
    "2) Добавить n-граммы\n",
    "3) Optimize choice for number of topics through coherence measure\n",
    "4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Scrapping\n",
    "\n",
    "В качестве объекта скреппинга выбран ресурс PubMed с биологическими статьями. Вытаскивать со странички буду название и abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_url_from_id = lambda idx: \"https://pubmed.ncbi.nlm.nih.gov/\" + str(idx) + \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_page(idx: str):\n",
    "    page = requests.get(get_url_from_id(idx)).text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    title = soup.title.text\n",
    "    \n",
    "    spans = soup.findAll('div')\n",
    "    abstract = None\n",
    "    classes = []\n",
    "    for span in spans:\n",
    "        try:\n",
    "            classes.extend(span['class'])\n",
    "            if 'abstract-content' in span['class']:\n",
    "                abstract = span\n",
    "                break\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    abstract = abstract.text\n",
    "    return title + ' ' + abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_article = 29949996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping 29949996\n",
      "Failed: 29949996\n",
      "Scrapping 29949997\n",
      "Failed: 29949997\n",
      "Scrapping 29949998\n",
      "Scrapping 29949999\n",
      "Scrapping 29950000\n",
      "Scrapping 29950001\n",
      "Scrapping 29950002\n",
      "Scrapping 29950003\n",
      "Scrapping 29950004\n",
      "Scrapping 29950005\n",
      "Scrapping 29950006\n",
      "Scrapping 29950007\n",
      "Scrapping 29950008\n",
      "Scrapping 29950009\n",
      "Scrapping 29950010\n",
      "Scrapping 29950011\n",
      "Scrapping 29950012\n",
      "Scrapping 29950013\n",
      "Scrapping 29950014\n",
      "Scrapping 29950015\n",
      "Failed: 29950015\n",
      "Scrapping 29950016\n",
      "Scrapping 29950017\n",
      "Scrapping 29950018\n",
      "Scrapping 29950019\n",
      "Scrapping 29950020\n",
      "Scrapping 29950021\n",
      "Scrapping 29950022\n",
      "Failed: 29950022\n",
      "Scrapping 29950023\n",
      "Failed: 29950023\n",
      "Scrapping 29950024\n",
      "Failed: 29950024\n",
      "Scrapping 29950025\n",
      "Failed: 29950025\n",
      "Scrapping 29950026\n",
      "Failed: 29950026\n",
      "Scrapping 29950027\n",
      "Failed: 29950027\n",
      "Scrapping 29950028\n",
      "Failed: 29950028\n",
      "Scrapping 29950029\n",
      "Scrapping 29950030\n",
      "Scrapping 29950031\n",
      "Scrapping 29950032\n",
      "Scrapping 29950033\n",
      "Scrapping 29950034\n",
      "Scrapping 29950035\n",
      "Scrapping 29950036\n",
      "Failed: 29950036\n",
      "Scrapping 29950037\n",
      "Scrapping 29950038\n",
      "Scrapping 29950039\n",
      "Scrapping 29950040\n",
      "Scrapping 29950041\n",
      "Scrapping 29950042\n",
      "Scrapping 29950043\n",
      "Scrapping 29950044\n",
      "Failed: 29950044\n",
      "Scrapping 29950045\n",
      "Scrapping 29950046\n",
      "Scrapping 29950047\n",
      "Scrapping 29950048\n",
      "Scrapping 29950049\n",
      "Scrapping 29950050\n",
      "Scrapping 29950051\n",
      "Scrapping 29950052\n",
      "Scrapping 29950053\n",
      "Failed: 29950053\n",
      "Scrapping 29950054\n",
      "Scrapping 29950055\n",
      "Scrapping 29950056\n",
      "Scrapping 29950057\n",
      "Scrapping 29950058\n",
      "Scrapping 29950059\n",
      "Scrapping 29950060\n",
      "Scrapping 29950061\n",
      "Scrapping 29950062\n",
      "Scrapping 29950063\n",
      "Scrapping 29950064\n",
      "Scrapping 29950065\n",
      "Scrapping 29950066\n",
      "Scrapping 29950067\n",
      "Scrapping 29950068\n",
      "Scrapping 29950069\n",
      "Scrapping 29950070\n",
      "Scrapping 29950071\n",
      "Scrapping 29950072\n",
      "Scrapping 29950073\n",
      "Scrapping 29950074\n",
      "Scrapping 29950075\n",
      "Scrapping 29950076\n",
      "Scrapping 29950077\n",
      "Scrapping 29950078\n",
      "Scrapping 29950079\n",
      "Scrapping 29950080\n",
      "Scrapping 29950081\n",
      "Scrapping 29950082\n",
      "Scrapping 29950083\n",
      "Scrapping 29950084\n",
      "Scrapping 29950085\n",
      "Scrapping 29950086\n",
      "Scrapping 29950087\n",
      "Scrapping 29950088\n",
      "Scrapping 29950089\n",
      "Scrapping 29950090\n",
      "Scrapping 29950091\n",
      "Scrapping 29950092\n",
      "Scrapping 29950093\n",
      "Scrapping 29950094\n",
      "Scrapping 29950095\n",
      "Scrapping 29950096\n",
      "Scrapping 29950097\n",
      "Scrapping 29950098\n",
      "Scrapping 29950099\n",
      "Scrapping 29950100\n",
      "Scrapping 29950101\n",
      "Scrapping 29950102\n",
      "Failed: 29950102\n",
      "Scrapping 29950103\n",
      "Scrapping 29950104\n",
      "Scrapping 29950105\n",
      "Scrapping 29950106\n",
      "Scrapping 29950107\n",
      "Failed: 29950107\n",
      "Scrapping 29950108\n",
      "Scrapping 29950109\n",
      "Scrapping 29950110\n",
      "Scrapping 29950111\n",
      "Scrapping 29950112\n",
      "Failed: 29950112\n",
      "Scrapping 29950113\n",
      "Failed: 29950113\n",
      "Scrapping 29950114\n",
      "Scrapping 29950115\n",
      "Scrapping 29950116\n",
      "Scrapping 29950117\n",
      "Scrapping 29950118\n",
      "Scrapping 29950119\n",
      "Scrapping 29950120\n",
      "Scrapping 29950121\n",
      "Scrapping 29950122\n",
      "Scrapping 29950123\n",
      "Scrapping 29950124\n",
      "Scrapping 29950125\n",
      "Scrapping 29950126\n",
      "Scrapping 29950127\n",
      "Scrapping 29950128\n",
      "Scrapping 29950129\n",
      "Scrapping 29950130\n",
      "Scrapping 29950131\n",
      "Failed: 29950131\n",
      "Scrapping 29950132\n",
      "Scrapping 29950133\n",
      "Scrapping 29950134\n",
      "Scrapping 29950135\n",
      "Failed: 29950135\n",
      "Scrapping 29950136\n",
      "Scrapping 29950137\n",
      "Scrapping 29950138\n",
      "Scrapping 29950139\n",
      "Scrapping 29950140\n",
      "Scrapping 29950141\n",
      "Scrapping 29950142\n",
      "Scrapping 29950143\n",
      "Scrapping 29950144\n",
      "Scrapping 29950145\n",
      "Scrapping 29950146\n",
      "Scrapping 29950147\n",
      "Scrapping 29950148\n",
      "Scrapping 29950149\n",
      "Scrapping 29950150\n",
      "Scrapping 29950151\n",
      "Scrapping 29950152\n",
      "Scrapping 29950153\n",
      "Scrapping 29950154\n",
      "Scrapping 29950155\n",
      "Failed: 29950155\n",
      "Scrapping 29950156\n",
      "Scrapping 29950157\n",
      "Scrapping 29950158\n",
      "Scrapping 29950159\n",
      "Scrapping 29950160\n",
      "Scrapping 29950161\n",
      "Scrapping 29950162\n",
      "Scrapping 29950163\n",
      "Scrapping 29950164\n",
      "Scrapping 29950165\n",
      "Scrapping 29950166\n",
      "Scrapping 29950167\n",
      "Scrapping 29950168\n",
      "Scrapping 29950169\n",
      "Scrapping 29950170\n",
      "Scrapping 29950171\n",
      "Scrapping 29950172\n",
      "Scrapping 29950173\n",
      "Scrapping 29950174\n",
      "Scrapping 29950175\n",
      "Scrapping 29950176\n",
      "Scrapping 29950177\n",
      "Scrapping 29950178\n",
      "Scrapping 29950179\n",
      "Scrapping 29950180\n",
      "Scrapping 29950181\n",
      "Scrapping 29950182\n",
      "Scrapping 29950183\n",
      "Scrapping 29950184\n",
      "Scrapping 29950185\n",
      "Scrapping 29950186\n",
      "Scrapping 29950187\n",
      "Scrapping 29950188\n",
      "Scrapping 29950189\n",
      "Scrapping 29950190\n",
      "Scrapping 29950191\n",
      "Scrapping 29950192\n",
      "Failed: 29950192\n",
      "Scrapping 29950193\n",
      "Scrapping 29950194\n",
      "Scrapping 29950195\n",
      "Scrapping 29950196\n",
      "Scrapping 29950197\n",
      "Scrapping 29950198\n",
      "Scrapping 29950199\n",
      "Scrapping 29950200\n",
      "Scrapping 29950201\n",
      "Scrapping 29950202\n",
      "Scrapping 29950203\n",
      "Scrapping 29950204\n",
      "Scrapping 29950205\n",
      "Scrapping 29950206\n",
      "Scrapping 29950207\n",
      "Scrapping 29950208\n",
      "Scrapping 29950209\n",
      "Scrapping 29950210\n",
      "Scrapping 29950211\n",
      "Scrapping 29950212\n",
      "Scrapping 29950213\n",
      "Scrapping 29950214\n",
      "Scrapping 29950215\n",
      "Scrapping 29950216\n",
      "Scrapping 29950217\n",
      "Scrapping 29950218\n",
      "Scrapping 29950219\n",
      "Scrapping 29950220\n",
      "Scrapping 29950221\n",
      "Scrapping 29950222\n",
      "Scrapping 29950223\n",
      "Scrapping 29950224\n",
      "Scrapping 29950225\n",
      "Scrapping 29950226\n",
      "Scrapping 29950227\n",
      "Scrapping 29950228\n",
      "Scrapping 29950229\n",
      "Scrapping 29950230\n",
      "Scrapping 29950231\n",
      "Scrapping 29950232\n",
      "Scrapping 29950233\n",
      "Scrapping 29950234\n",
      "Scrapping 29950235\n",
      "Scrapping 29950236\n",
      "Scrapping 29950237\n",
      "Scrapping 29950238\n",
      "Scrapping 29950239\n",
      "Scrapping 29950240\n",
      "Scrapping 29950241\n",
      "Scrapping 29950242\n",
      "Scrapping 29950243\n",
      "Scrapping 29950244\n",
      "Scrapping 29950245\n",
      "Scrapping 29950246\n",
      "Scrapping 29950247\n",
      "Scrapping 29950248\n",
      "Scrapping 29950249\n",
      "Scrapping 29950250\n",
      "Failed: 29950250\n",
      "Scrapping 29950251\n",
      "Scrapping 29950252\n",
      "Scrapping 29950253\n",
      "Scrapping 29950254\n",
      "Scrapping 29950255\n",
      "Scrapping 29950256\n",
      "Scrapping 29950257\n",
      "Scrapping 29950258\n",
      "Scrapping 29950259\n",
      "Scrapping 29950260\n",
      "Scrapping 29950261\n",
      "Scrapping 29950262\n",
      "Scrapping 29950263\n",
      "Scrapping 29950264\n",
      "Scrapping 29950265\n",
      "Scrapping 29950266\n",
      "Scrapping 29950267\n",
      "Scrapping 29950268\n",
      "Scrapping 29950269\n",
      "Failed: 29950269\n",
      "Scrapping 29950270\n",
      "Failed: 29950270\n",
      "Scrapping 29950271\n",
      "Failed: 29950271\n",
      "Scrapping 29950272\n",
      "Failed: 29950272\n",
      "Scrapping 29950273\n",
      "Scrapping 29950274\n",
      "Scrapping 29950275\n",
      "Scrapping 29950276\n",
      "Scrapping 29950277\n",
      "Scrapping 29950278\n",
      "Scrapping 29950279\n",
      "Scrapping 29950280\n",
      "Scrapping 29950281\n",
      "Scrapping 29950282\n",
      "Scrapping 29950283\n",
      "Scrapping 29950284\n",
      "Scrapping 29950285\n",
      "Scrapping 29950286\n",
      "Scrapping 29950287\n",
      "Scrapping 29950288\n",
      "Scrapping 29950289\n",
      "Scrapping 29950290\n",
      "Scrapping 29950291\n",
      "Scrapping 29950292\n",
      "Scrapping 29950293\n",
      "Scrapping 29950294\n",
      "Failed: 29950294\n",
      "Scrapping 29950295\n",
      "Failed: 29950295\n",
      "Scrapping 29950296\n",
      "Failed: 29950296\n",
      "Scrapping 29950297\n",
      "Failed: 29950297\n",
      "Scrapping 29950298\n",
      "Scrapping 29950299\n",
      "Scrapping 29950300\n",
      "Scrapping 29950301\n",
      "Failed: 29950301\n",
      "Scrapping 29950302\n",
      "Scrapping 29950303\n",
      "Scrapping 29950304\n",
      "Scrapping 29950305\n",
      "Scrapping 29950306\n",
      "Scrapping 29950307\n",
      "Failed: 29950307\n",
      "Scrapping 29950308\n",
      "Failed: 29950308\n",
      "Scrapping 29950309\n",
      "Scrapping 29950310\n",
      "Scrapping 29950311\n",
      "Failed: 29950311\n",
      "Scrapping 29950312\n",
      "Failed: 29950312\n",
      "Scrapping 29950313\n",
      "Failed: 29950313\n",
      "Scrapping 29950314\n",
      "Scrapping 29950315\n",
      "Scrapping 29950316\n",
      "Scrapping 29950317\n",
      "Scrapping 29950318\n",
      "Scrapping 29950319\n",
      "Scrapping 29950320\n",
      "Scrapping 29950321\n",
      "Scrapping 29950322\n",
      "Failed: 29950322\n",
      "Scrapping 29950323\n",
      "Scrapping 29950324\n",
      "Scrapping 29950325\n",
      "Failed: 29950325\n",
      "Scrapping 29950326\n",
      "Failed: 29950326\n",
      "Scrapping 29950327\n",
      "Scrapping 29950328\n",
      "Scrapping 29950329\n",
      "Failed: 29950329\n",
      "Scrapping 29950330\n",
      "Scrapping 29950331\n",
      "Scrapping 29950332\n",
      "Scrapping 29950333\n",
      "Scrapping 29950334\n",
      "Scrapping 29950335\n",
      "Failed: 29950335\n",
      "Scrapping 29950336\n"
     ]
    }
   ],
   "source": [
    "cntr = 0\n",
    "articles = []\n",
    "idx = start_article\n",
    "while cntr < 300:\n",
    "#     time.sleep(1)\n",
    "    try:\n",
    "        print(f\"Scrapping {idx}\")\n",
    "        txt = get_text_from_page(idx)\n",
    "        articles.append(txt)\n",
    "        cntr+=1\n",
    "        idx+=1\n",
    "    except Exception:\n",
    "        print(f\"Failed: {idx}\")\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('scrapped_data.pickle', 'wb') as f:\n",
    "    pickle.dump(articles, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Text preprocessing\n",
    "\n",
    "### Plan:\n",
    "1. Tokenize\n",
    "2. Remove punctuation\n",
    "3. Hybride stemming\n",
    "4. Remmove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = articles.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [nltk.word_tokenize(text) for text in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Remove puctuation tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = string.punctuation + \"``\" + \"\\'\\'\" + \"...\" + \"....\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [list(filter(lambda token: token not in punc, text)) for text in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chech whether all punctuation symbols removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for text in corpus:\n",
    "    words.extend(text)\n",
    "words = list(set(words))\n",
    "words.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-0.005',\n",
       " '-0.675',\n",
       " '-1-aminopropan-2-ol',\n",
       " '-10',\n",
       " '-13',\n",
       " '-2',\n",
       " '-25',\n",
       " '-4',\n",
       " '-7',\n",
       " '-Editorial']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[20:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что осталось много специфических символов, чисел, поскольку они часто встречаются в статьях, но не несут почти никакого смысла. Поэтому просто уберу их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:5: DeprecationWarning: invalid escape sequence \\W\n",
      "<>:4: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:5: DeprecationWarning: invalid escape sequence \\W\n",
      "<>:4: DeprecationWarning: invalid escape sequence \\d\n",
      "<>:5: DeprecationWarning: invalid escape sequence \\W\n",
      "<ipython-input-108-0249e7312b14>:4: DeprecationWarning: invalid escape sequence \\d\n",
      "  word = re.sub('\\d', \"\", wrd)\n",
      "<ipython-input-108-0249e7312b14>:5: DeprecationWarning: invalid escape sequence \\W\n",
      "  word = re.sub('\\W', \"\", word)\n"
     ]
    }
   ],
   "source": [
    "def filter_text_from_punct(txt: List[str]) -> List[str]:\n",
    "    result = []\n",
    "    for wrd in txt:\n",
    "        word = re.sub('\\d', \"\", wrd)\n",
    "        word = re.sub('\\W', \"\", word)\n",
    "        if (len(word) > 0):\n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [filter_text_from_punct(text) for text in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import krovetz\n",
    "ks = krovetz.PyKrovetzStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [[ks.stem(i) for i in text] for text in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Drop stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [[word for word in text if word not in stopwords] for text in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Drop short word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for text in corpus:\n",
    "    words.extend(text)\n",
    "words = list(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b',\n",
       " 'c',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'n',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 'u',\n",
       " 'v',\n",
       " 'x',\n",
       " 'z',\n",
       " 'Å',\n",
       " 'Φ',\n",
       " 'β',\n",
       " 'γ',\n",
       " 'κ',\n",
       " 'λ',\n",
       " '⁶',\n",
       " 'aa',\n",
       " 'ac',\n",
       " 'ad',\n",
       " 'ag',\n",
       " 'ah',\n",
       " 'ai']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(words, key=len)[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Довольно много одиночных букв (которые точно надо убрать) и слов длины два. Часть из слов длины 2 может быть важна, но среди них может быть и мусор, поэтому почищу их все."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text_from_short(txt: List[str]) -> List[str]:\n",
    "    result = []\n",
    "    for wrd in txt:\n",
    "        if (len(wrd) > 2):\n",
    "            result.append(wrd)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [filter_text_from_short(text) for text in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем словарь и векторизуем его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  создаем словарь \n",
    "dictionary = corpora.Dictionary(corpus)\n",
    "corpus = [dictionary.doc2bow(text) for text in corpus]\n",
    "tfidf_model = models.TfidfModel(corpus)\n",
    "tfidf = tfidf_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling\n",
    "## 1. LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TOPICS = 5\n",
    "ldamodel = models.LdaModel(tfidf, id2word=dictionary, num_topics=NUM_TOPICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.001*\"health\" + 0.001*\"patient\" + 0.001*\"bone\" + 0.001*\"cell\"')\n",
      "(1, '0.001*\"patient\" + 0.001*\"cell\" + 0.001*\"expression\" + 0.001*\"women\"')\n",
      "(2, '0.001*\"patient\" + 0.001*\"gene\" + 0.001*\"group\" + 0.001*\"cancer\"')\n",
      "(3, '0.001*\"group\" + 0.001*\"patient\" + 0.001*\"cell\" + 0.001*\"expression\"')\n",
      "(4, '0.001*\"cell\" + 0.001*\"hiv\" + 0.001*\"ato\" + 0.001*\"health\"')\n"
     ]
    }
   ],
   "source": [
    "topics = ldamodel.print_topics(num_words=4)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(model, tfidf):\n",
    "    m_score = 0\n",
    "    for index, score in sorted(model[tfidf[1]], key=lambda tup: -1*tup[1]):\n",
    "        if score > m_score:\n",
    "            m_score = score\n",
    "            m_topic = index\n",
    "    return m_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.001*\"patient\" + 0.001*\"group\" + 0.001*\"case\" + 0.001*\"ato\"'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_model = []\n",
    "lda.print_topic(get_topics(ldamodel, tfidf), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyLDAvis.enable_notebook()\n",
    "# vis = pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary=ldamodel.id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '0.231*\"patient\" + 0.194*\"cell\" + 0.174*\"expression\"'),\n",
       " (1, '0.289*\"health\" + -0.223*\"cell\" + -0.207*\"expression\"'),\n",
       " (2, '-0.263*\"patient\" + 0.197*\"cell\" + -0.156*\"aml\"'),\n",
       " (3, '-0.354*\"health\" + -0.241*\"mental\" + -0.160*\"cell\"'),\n",
       " (4, '0.289*\"decoction\" + 0.189*\"guizhi\" + 0.183*\"disease\"')]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import models\n",
    "lsi = models.LsiModel(tfidf, id2word=dictionary, num_topics=5)\n",
    "lsi.show_topics(num_words=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x7fa7ecd70950>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
